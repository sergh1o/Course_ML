{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Превращение «черного ящика» в «белый ящик»: пути решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При рассмотрении дерева решений интуитивно понятно, что для каждого решения, принимаемого деревом (или лесом), имеется путь (или пути) от корня дерева до листа. Путь состоит из серии решений, полученных с помощью конкретного признака, каждый из которых вносит свой вклад в итоговый прогноз.\n",
    "Дерево решений с $M$ листьями делит пространство на $M$ областей $R_m$, 1 ≤ $m$ ≤ $M$. В классическом определении (например,  в классическом труде «Elements of Statistical Learning») прогнозная функция дерева определяется так:\n",
    "\n",
    "$\\Large F(x) = \\sum_{M=1}^m C_mI(x,R_m)$\n",
    "\n",
    "где:\n",
    "\n",
    "$M$ - количество листьев в дереве (т.е. области в пространстве признаков);\n",
    "\n",
    "$R_m$ - область в пространстве признаков (соответствующая листу $m$);\n",
    "\n",
    "$c_m$ - константа, соответствующая области $m$;\n",
    "\n",
    "$I$ - индикаторная функция (возвращающая 1, если $x$ $\\in$ $R_m$, 0 в противном случае). \n",
    "\n",
    "Значение $c_m$ определяется на этапе обучения дерева и в случае деревьев регрессии соответствует среднему значению зависимой переменной в выборке наблюдений, относящейся к области $R_m$ (в случае дерева классификации значение cm соответствует пропорциям классов зависимой переменной). Определение краткое и фиксирует содержательный смысл дерева: решающая функция возвращает значение в правильном листе дерева. Однако это определение игнорирует наличие путей, проходящих через узлы-решения, и информацию, содержащуюся в них.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример: данные о ценах на жилье в Бостоне"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте возьмем набор данных о ценах на жилье в Бостоне, который включает цены на жилье в пригородах Бостона, а также ряд ключевых признаков, таких как качество воздуха (переменная `NOX`), расстояние до центра города (`DIS`) и ряд других. Мы построим дерево регрессии (глубина 3 взята для удобства чтения), чтобы предсказать цены на жилье. Как обычно, у дерева есть условия для каждого внутреннего узла и значение, связанное с каждым листом (то есть спрогнозированное значение). Но дополнительно мы выведем значение в каждом внутреннем узле, то есть среднее значение зависимой переменной в этой области.\n",
    "\n",
    "\n",
    "<img src='img/picture.png'>\n",
    "\n",
    "\n",
    "Ниже вы увидите прогноз, записанный с точки зрения изменений среднего значения зависимой переменной вдоль пути прогнозирования (выделен на рисунке красным), вместе с названиями признаков, которые обусловили изменение среднего значения (числа являются приблизительными из-за округления).\n",
    "\n",
    "\n",
    "<img src='img/picture2.png'>\n",
    "\n",
    "\n",
    "Этот пример показывает, что существует еще один, более компактный способ вычисления прогнозов, а именно вычисление прогноза с помощью последовательности областей, соответствующих каждому узлу/решению дерева. Поскольку каждое решение принимается функцией и решение либо увеличивает, либо уменьшает значение зависимой переменной, начиная с родительского узла, то прогноз может быть определен как сумма вкладов признаков плюс «смещение» (то есть среднее значение зависимой переменной в корневом узле, который охватывает весь обучающий набор).\n",
    "\n",
    "Прогнозную функцию можно записать как\n",
    "\n",
    "$\\Large F(x) = c + \\sum_{k=1}^K contrib(x,k)$\n",
    "\n",
    "где\n",
    "\n",
    "$K$ - количество признаков;\n",
    "\n",
    "$c$ - значение зависимой переменной в корневом узле;\n",
    "\n",
    "$contrib(x,k)$ - вклад $k$-го признака в векторе признаков $x$.\n",
    "\n",
    "Это немного похоже на формулу линейной регрессии  $f(x) = a + bx$. Для линейной регрессии коэффициенты $b$ фиксированы, каждый признак имеет определенный вес, который определяет вклад признака. Для дерева решений вклад каждого признака не является конкретным определенным значением, однако зависит от остальных признаков, определяющих путь решения, который проходит вдоль дерева и, следовательно, учитывает вклады признаков, которые встречаются на пути.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### От деревьев решений к случайному лесу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, каким образом мы можем перейти от дерева решений к случайному лесу? Это довольно просто, поскольку прогнозом леса является усредненный прогноз его деревьев:\n",
    "\n",
    "$\\Large F(x) = \\frac{1}{J} \\sum_{j=1}^J f_i(x)$\n",
    "\n",
    "где\n",
    "\n",
    "$J$ - это количество деревьев в лесу.\n",
    "\n",
    "Исходя из этой формулы, легко увидеть, что для леса прогноз – это просто усредненное смещение плюс усредненный вклад каждого признака:\n",
    "\n",
    "$\\Large F(x) = \\frac{1}{J}\\sum_{j=1}^J c_j + \\sum_{k=1}^K(\\frac{1}{J} \\sum_{j=1}^Jcontrib_j(x,k))$\n",
    "\n",
    "$c_j$ - значение зависимой переменной в корневом узле $j$-ного дерева леса.\n",
    "\n",
    "Алгоритм интерпретации случайного леса реализован в питоновском пакете `treeinterpreter` (устанавливается с помощью команды `pip install treeinterpreter`), который выполняет декомпозицию прогнозов, полученных с помощью дерева решений или случайного леса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем необходимые библиотеки и классы (treeinterpreter можно \n",
    "# установить с помощью команды pip install treeinterpreter)\n",
    "from treeinterpreter import treeinterpreter as ti\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загружаем данные для задачи регрессии\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "# обучаем ансамбль деревьев регрессии\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(boston.data, boston.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отдельно запишем наблюдение, для которого будем смотреть прогноз\n",
    "observation = boston.data[300:301]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прогноз для наблюдения: [26.36]\n"
     ]
    }
   ],
   "source": [
    "# печатаем прогноз для наблюдения\n",
    "print(\"Прогноз для наблюдения:\", rf.predict(observation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прогноз [[26.36]]\n",
      "Смещение (среднее зависимой переменной в обучающем наборе) [22.63029644]\n",
      "Вклады признаков:\n",
      "CRIM -0.3360322270322268\n",
      "ZN -0.03758974358974321\n",
      "INDUS 0.1738911541889479\n",
      "CHAS 0.0\n",
      "NOX 0.25131732228760806\n",
      "RM 2.9133520427656747\n",
      "AGE -0.8093400809716602\n",
      "DIS -1.576270071161994\n",
      "RAD 0.0\n",
      "TAX -0.3011648606619328\n",
      "PTRATIO 0.0018204192462256685\n",
      "B -0.06514957264957282\n",
      "LSTAT 3.5148691748909195\n"
     ]
    }
   ],
   "source": [
    "# выполним декомпозицию прогноза для наблюдения\n",
    "prediction, bias, contributions = ti.predict(rf, observation)\n",
    "# печатаем результаты декомпозиции прогноза\n",
    "print(\"Прогноз\", prediction)\n",
    "print(\"Смещение (среднее зависимой переменной в обучающем наборе)\", bias)\n",
    "print(\"Вклады признаков:\")\n",
    "for c, feature in zip(contributions[0], boston.feature_names):\n",
    "    print(feature, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Смещение (среднее зависимой переменной в обучающем наборе) [22.63029644]\n",
      "Вклады признаков:\n",
      "LSTAT 3.51\n",
      "RM 2.91\n",
      "DIS -1.58\n",
      "AGE -0.81\n",
      "CRIM -0.34\n",
      "TAX -0.3\n",
      "NOX 0.25\n",
      "INDUS 0.17\n",
      "B -0.07\n",
      "ZN -0.04\n",
      "PTRATIO 0.0\n",
      "CHAS 0.0\n",
      "RAD 0.0\n"
     ]
    }
   ],
   "source": [
    "# печатаем результаты декомпозиции прогноза, отсортировав \n",
    "# вклады признаков по убыванию абсолютного значения и \n",
    "# выполнив округление до второго знака\n",
    "print(\"Смещение (среднее зависимой переменной в обучающем наборе)\", bias)\n",
    "print(\"Вклады признаков:\")\n",
    "for c, feature in sorted(zip(contributions[0], \n",
    "                             boston.feature_names), \n",
    "                             key=lambda x: -abs(x[0])):\n",
    "    print(feature, round(c, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вклады отсортированы по уменьшению абсолютных значений вкладов. Здесь мы видим, что наибольшим положительным вкладом обладают предикторы `LSTAT` и `RM`, то есть они в наибольшей степени увеличивают прогнозное значение зависимой переменной для данного наблюдения. При этом для другого взятого наблюдения может быть обратная ситуация: эти предикторы могут значительно уменьшать прогнозное значение зависимой переменной. Таким образом, между вкладами признаков нельзя проводить аналогию с регрессионными коэффициентами, которые будут для всех наблюдений одинаковыми. Нельзя сказать, что всегда с возрастанием значений переменных `LSTAT` и `RM` будет увеличиваться цена на жилье. Если дальше смотреть на вывод, то видно, что наибольший отрицательный вклад дает переменная `DIS`. Опять же помним, что для другого наблюдения эта переменная может дать положительный вклад. \n",
    "\n",
    "Давайте проверим, корректна ли декомпозиция прогноза. Для этого мы должны сложить смещение и вклады признаков и получить в сумме спрогнозированное значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26.36]]\n",
      "[26.36]\n"
     ]
    }
   ],
   "source": [
    "# сложим смещение и вклады признаков, чтобы проверить,\n",
    "# совпадает ли полученный результат с прогнозом\n",
    "print(prediction)\n",
    "print(bias + np.sum(contributions, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат сложения совпадает со спрогнозированным значением. Теперь загрузим данные о заемщиках банка для решения задачи классификации и построим ансамбль деревьев классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загружаем данные для задачи классификации \n",
    "# в пандасовский DataFrame\n",
    "data = pd.read_csv(\"Data/BankloanPy.csv\", encoding='cp1251', sep=';')\n",
    "# формируем массив признаков и массив меток\n",
    "y = data.loc[:, 'default']\n",
    "X = data.loc[:, 'age':'othdebt']\n",
    "# записываем названия признаков, чтобы потом \n",
    "# сопоставить их значениям вкладов\n",
    "features_names = X.columns\n",
    "# разбиваем на обучение и тест\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# обучаем ансамбль деревьев классификации\n",
    "forest = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прогноз [[0.95 0.05]]\n",
      "Смещения (фактические доли классов в обучающем наборе) [[0.64397143 0.35602857]]\n",
      "Вклады признаков:\n",
      "age [ 0.04751199 -0.04751199]\n",
      "employ [ 0.07158361 -0.07158361]\n",
      "address [ 0.0427569 -0.0427569]\n",
      "income [ 0.04874334 -0.04874334]\n",
      "debtinc [ 0.07574518 -0.07574518]\n",
      "creddebt [ 0.00998228 -0.00998228]\n",
      "othdebt [ 0.00970526 -0.00970526]\n"
     ]
    }
   ],
   "source": [
    "# печатаем результаты декомпозиции прогноза \n",
    "# для конкретного наблюдения\n",
    "prediction_test, bias_test, contributions_test = ti.predict(forest, X_test[100:101])\n",
    "print(\"Прогноз\", prediction_test)\n",
    "print(\"Смещения (фактические доли классов в обучающем наборе)\", bias_test)\n",
    "print(\"Вклады признаков:\")\n",
    "for c, feature in zip(contributions_test[0], features_names):\n",
    "    print(feature, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Из вывода видно, что мы получаем значения смещения и вклады признаков по двум классам зависимой переменной. Значение смещения в каждом классе – это фактическая доля соответствующего класса зависимой переменной в выборке. Вклады признаков в каждом классе  показывают, в какой степени те или иные признаки увеличивают или уменьшают вероятность соответствующего класса. Значения вкладов конкретного признака по классам зеркальны, что логично: переменная `age` на 0,05 увеличивает вероятность отрицательного класса (вероятность того, что заемщик окажется «хорошим)», что эквивалентно уменьшению вероятности положительного класса (вероятности того, что заемщик окажется «плохим») на 0,05. И вновь вспомним, что такая картина верна только для данного наблюдения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
