{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем библиотеки pandas и numpy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer Lifetime Value</th>\n",
       "      <th>Income</th>\n",
       "      <th>Monthly Premium Auto</th>\n",
       "      <th>Months Since Last Claim</th>\n",
       "      <th>Months Since Policy Inception</th>\n",
       "      <th>Number of Open Complaints</th>\n",
       "      <th>Number of Policies</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18975.456110</td>\n",
       "      <td>65999</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4715.321344</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>19</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5018.885233</td>\n",
       "      <td>54500</td>\n",
       "      <td>63</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer Lifetime Value  Income  Monthly Premium Auto  \\\n",
       "0             18975.456110   65999                   237   \n",
       "1              4715.321344       0                    65   \n",
       "2              5018.885233   54500                    63   \n",
       "\n",
       "   Months Since Last Claim  Months Since Policy Inception  \\\n",
       "0                        1                             14   \n",
       "1                       19                             56   \n",
       "2                       28                             17   \n",
       "\n",
       "   Number of Open Complaints  Number of Policies  Response  \n",
       "0                          0                   6         0  \n",
       "1                          0                   3         0  \n",
       "2                          0                   6         0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# записываем CSV-файл в объект DataFrame\n",
    "data = pd.read_csv('Data/StateFarm.csv', sep=';')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем функцию train_test_split(), с помощью\n",
    "# которой разбиваем данные на обучающие и тестовые\n",
    "from sklearn.model_selection import train_test_split\n",
    "# разбиваем данные на обучающие и тестовые: получаем обучающий\n",
    "# массив признаков, тестовый массив признаков, обучающий массив\n",
    "# меток, тестовый массив меток\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('Response', axis=1), \n",
    "                                                    data['Response'], \n",
    "                                                    test_size=0.3,\n",
    "                                                    stratify=data['Response'],\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем класс StandardScaler, выполняющий стандартизацию\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# создаем модель стандартизации – экземпляр класса StandardScaler\n",
    "standardscaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# обучаем модель стандартизации, т.е. по каждому признаку \n",
    "# в обучающем массиве признаков вычисляем\n",
    "# среднее значение признака и стандартное \n",
    "# отклонение признака для трансформации\n",
    "standardscaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# применяем модель стандартизации к обучающему массиву признаков: из исходного \n",
    "# значения признака вычитаем среднее значение признака, вычисленное \n",
    "# по ОБУЧАЮЩЕМУ массиву признаков, и результат делим на стандартное \n",
    "#отклонение признака, вычисленное по ОБУЧАЮЩЕМУ массиву признаков \n",
    "X_train_standardscaled = standardscaler.transform(X_train)\n",
    "\n",
    "# применяем модель стандартизации к тестовому массиву признаков: из исходного \n",
    "# значения признака вычитаем среднее значение признака, вычисленное \n",
    "# по ОБУЧАЮЩЕМУ массиву признаков, и результат делим на стандартное \n",
    "# отклонение признака, вычисленное по ОБУЧАЮЩЕМУ массиву признаков \n",
    "X_test_standardscaled = standardscaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правильность на обучающей выборке: 0.900\n",
      "Правильность на тестовой выборке: 0.900\n"
     ]
    }
   ],
   "source": [
    "# импортируем класс LogisticRegression,\n",
    "# строящий логистическую регрессию\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# создаем модель логистической регрессии – экземпляр класса LogisticRegression\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=200)\n",
    "# обучаем модель логистической регрессии, т.е. \n",
    "# находим параметры - регрессионные коэффициенты\n",
    "logreg.fit(X_train_standardscaled, y_train)\n",
    "# оцениваем качество модели на обучающих данных\n",
    "print('Правильность на обучающей выборке: {:.3f}'.format(\n",
    "    logreg.score(X_train_standardscaled, y_train)))\n",
    "# оцениваем качество модели на тестовых данных\n",
    "print('Правильность на тестовой выборке: {:.3f}'.format(\n",
    "    logreg.score(X_test_standardscaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вычисляем спрогнозированные значения зависимой переменной\n",
    "# для тестового массива признаков\n",
    "logreg_predvalues = logreg.predict(X_test_standardscaled)\n",
    "logreg_predvalues[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91027855, 0.08972145],\n",
       "       [0.89847518, 0.10152482],\n",
       "       [0.88300257, 0.11699743],\n",
       "       [0.90234211, 0.09765789],\n",
       "       [0.92554507, 0.07445493]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вычисляем спрогнозированные вероятности классов зависимой переменной\n",
    "# для тестового массива признаков\n",
    "logreg_probabilities = logreg.predict_proba(X_test_standardscaled)\n",
    "logreg_probabilities[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правильность на обучающей выборке: 0.900\n",
      "Правильность на тестовой выборке: 0.900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmaxscaler = MinMaxScaler()\n",
    "minmaxscaler.fit(X_train)\n",
    "X_train_minmaxscaled = minmaxscaler.transform(X_train)\n",
    "X_test_minmaxscaled = minmaxscaler.transform(X_test)\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=200)\n",
    "logreg.fit(X_train_minmaxscaled, y_train)\n",
    "print('Правильность на обучающей выборке: {:.3f}'.format(\n",
    "    logreg.score(X_train_minmaxscaled, y_train)))\n",
    "print('Правильность на тестовой выборке: {:.3f}'.format(\n",
    "    logreg.score(X_test_minmaxscaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правильность на обучающей выборке: 0.900\n",
      "Правильность на тестовой выборке: 0.900\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "robustscaler = RobustScaler()\n",
    "robustscaler.fit(X_train)\n",
    "X_train_robustscaled = robustscaler.transform(X_train)\n",
    "X_test_robustscaled = robustscaler.transform(X_test)\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=200)\n",
    "logreg.fit(X_train_robustscaled, y_train)\n",
    "print('Правильность на обучающей выборке: {:.3f}'.format(\n",
    "    logreg.score(X_train_robustscaled, y_train)))\n",
    "print('Правильность на тестовой выборке: {:.3f}'.format(\n",
    "    logreg.score(X_test_robustscaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
